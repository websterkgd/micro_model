{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    " #import packages for data analysis \n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from collections import deque\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the microsoft stock data\n",
    "MSFT_d = pd.read_csv('MSFT_20100622-20200626.csv') \n",
    "MSFT_r = pd.read_csv('MSFT_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize data to proportional changes Adj Close and volume\n",
    "MSFT_d['PctChange'] = MSFT_d['Adj Close'].pct_change()\n",
    "MSFT_d['VolChange'] = MSFT_d['Volume'].pct_change()\n",
    "MSFT_d.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the values \n",
    "MSFT_d['PctChange'] = preprocessing.scale(MSFT_d['PctChange'].values)\n",
    "MSFT_d['VolChange'] = preprocessing.scale(MSFT_d['VolChange'].values)\n",
    "MSFT_d.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull out firm from firm_rating\n",
    "Firm = []\n",
    "for i in MSFT_r['Firm_Rating']:\n",
    "    sep = ':'\n",
    "    v = i.split(sep, 1)[0]\n",
    "    Firm.append(v)\n",
    "    \n",
    "MSFT_r['Firm'] = Firm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename Bank oferica to Bank of America\n",
    "MSFT_r.Firm = MSFT_r.Firm.replace('Bank oferica', 'Bank of America')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull out rating from firm_rating\n",
    "#change firm_rating 255 to Nuetral\n",
    "MSFT_r['Firm_Rating'][255] = 'Nomura: to Neutral'\n",
    "Rating = []\n",
    "for i in MSFT_r['Firm_Rating']:\n",
    "    sep = 'to '\n",
    "    v = i.split(sep, 1)[1]\n",
    "    Rating.append(v)\n",
    "    \n",
    "MSFT_r['Rating'] = Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding ratings, firms, up_down, into one hot encoders\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode firm\n",
    "label_encoder = LabelEncoder()\n",
    "firm_ie = label_encoder.fit_transform(MSFT_r.Firm) #integer encoding firm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode firm\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "firm_ie = firm_ie.reshape(len(firm_ie), 1)\n",
    "firm_oe = onehot_encoder.fit_transform(firm_ie)\n",
    "firm_oe = pd.DataFrame(firm_oe, columns = label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode Rating\n",
    "label_encoder = LabelEncoder()\n",
    "rating_ie = label_encoder.fit_transform(MSFT_r.Rating) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode Rating\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "rating_ie = rating_ie.reshape(len(rating_ie), 1)\n",
    "rating_oe = onehot_encoder.fit_transform(rating_ie)\n",
    "rating_oe = pd.DataFrame(rating_oe, columns = label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode up_down\n",
    "label_encoder = LabelEncoder()\n",
    "up_down_ie = label_encoder.fit_transform(MSFT_r.Up_Down) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode up_down\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "up_down_ie = up_down_ie.reshape(len(up_down_ie), 1)\n",
    "up_down_oe = onehot_encoder.fit_transform(up_down_ie)\n",
    "up_down_oe = pd.DataFrame(up_down_oe, columns = label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add one hot encoders to MSFT_r\n",
    "MSFT_woe = pd.concat([MSFT_r, firm_oe, rating_oe, up_down_oe], \n",
    "                     axis=1, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting dates to datetime\n",
    "MSFT_woe.Date = pd.to_datetime(MSFT_woe.Date)\n",
    "MSFT_d.Date = pd.to_datetime(MSFT_d.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting the data on the same timescales and indices\n",
    "idx = pd.date_range(start = MSFT_woe.Date.iloc[-1], end = MSFT_d.Date.iloc[-1])\n",
    "MSFT_woe = MSFT_woe.reindex(idx, fill_value=0)\n",
    "\n",
    "MSFT_d.index = MSFT_d.Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joing the dataframes into predictive dataframe\n",
    "MSFT_x = pd.concat([MSFT_woe, MSFT_d], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choosing interval to predict and sequence length\n",
    "seq_len = 60\n",
    "fut_pred = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a future column\n",
    "fut_class = []\n",
    "for i in list(range(0,(len(MSFT_x.index)-3))):\n",
    "    v = 0\n",
    "    if MSFT_x['Adj Close'][i+3] > MSFT_x['Adj Close'][i]:\n",
    "        v = 1\n",
    "    else: v = 0\n",
    "    fut_class.append(v)\n",
    "    \n",
    "fut_class.append(np.NaN)\n",
    "fut_class.append(np.NaN)\n",
    "fut_class.append(np.NaN)\n",
    "\n",
    "MSFT_x['target'] = fut_class\n",
    "MSFT_x.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns that are problematic\n",
    "MSFT_x = MSFT_x.drop(['Date', 'Up_Down', 'Firm', 'Rating',\n",
    "                      'Firm_Rating', 'Open', 'High', 'Low',\n",
    "                      'Close', 'Adj Close', 'Volume'], axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building RNN\n",
    "\n",
    "#importing packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Dropout, LSTM, BatchNormalization \n",
    "#for output and layers \n",
    "from keras.models import Sequential # for RNN\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from collections import deque\n",
    "from keras.optimizers import Adam\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    " #cutting last 10 % of data to predict on\n",
    "L_10 = MSFT_x[int(0.9*len(MSFT_x.index)):]\n",
    "\n",
    "test_x = MSFT_x[:(int(0.9*len(MSFT_x.index))-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function to get training and test data for RNN\n",
    "def dataprep(df):\n",
    "    sequential_data = []\n",
    "    prev_days = deque(maxlen=seq_len)\n",
    "    for i in df.values:\n",
    "        prev_days.append([n for n in i[:-1]])\n",
    "        if len(prev_days) == seq_len:\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])\n",
    "            \n",
    "    random.shuffle(sequential_data)\n",
    "    \n",
    "    #balance the data\n",
    "    buys = []\n",
    "    sells = []\n",
    "    \n",
    "    for seq, target in sequential_data:\n",
    "        if target == 0:\n",
    "            sells.append([seq, target])\n",
    "        elif target == 1:\n",
    "            buys.append([seq, target])\n",
    "   \n",
    "    random.shuffle(buys)\n",
    "    random.shuffle(sells)\n",
    "    \n",
    "    lower = min(len(buys), len(sells))\n",
    "    \n",
    "    buys = buys[:lower]\n",
    "    sells = sells[:lower]\n",
    "    \n",
    "    sequential_data = buys+sells\n",
    "    \n",
    "    random.shuffle(sequential_data)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for seq, target in sequential_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    \n",
    "    return np.array(X), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN info\n",
    "Epochs = 10\n",
    "Batch_size = 64\n",
    "name = \"{}-seq-{}-pred-{}\".format(seq_len, fut_pred, int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dataframes\n",
    "X_train, y_train = dataprep(test_x)\n",
    "X_test, y_test = dataprep(L_10)\n",
    "\n",
    "y_train_binary = to_categorical(y_train)\n",
    "y_test_binary = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/25 [=>............................] - ETA: 6s - loss: 1.0446 - accuracy: 0.4922WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.213483). Check your callbacks.\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.8616 - accuracy: 0.5182INFO:tensorflow:Assets written to: models/RNN_trial-01-0.50.hdf5.model\\assets\n",
      "25/25 [==============================] - 7s 299ms/step - loss: 0.8616 - accuracy: 0.5182 - val_loss: 0.6995 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# rnn model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(128, input_shape = X_train.shape[1:], activation = 'relu',\n",
    "               return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128, input_shape = X_train.shape[1:], activation = 'relu',\n",
    "                    return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128, input_shape = X_train.shape[1:], activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation ='softmax'))\n",
    "\n",
    "model.compile(loss ='categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy']) \n",
    "\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(name))\n",
    "\n",
    "filepath =  \"RNN_trial-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath,\n",
    "                             monitor = \"val_accuracy\", verbose = 1))\n",
    "\n",
    "history = model.fit(X_train, y_train_binary, batch_size = Batch_size, \n",
    "                    validation_data = (X_test, y_test_binary),  \n",
    "                    callbacks = [tensorboard, checkpoint])\n",
    "\n",
    "#model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
